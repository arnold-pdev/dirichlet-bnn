using Statistics
using SpecialFunctions, Distributions
using Flux, Flux.Optimise
using Flux: params
using Base.Iterators: partition
using LinearAlgebra
using CSV, DataFrames, BSON
using Plots

# load data
# make sure to prepare the data by removing "< 0.01", etc
data = CSV.read("chemcam-data/ChemCam_PCA_composition.csv", DataFrame)
# replace 0.0 with 0.0001 in data_y
data_y = [ vcat([ maximum([data[i, j],0.001]) for j in 3:10 ], 
[maximum([0.001,100.0-sum([ data[i, j] for j in 3:10 ])])]) for i in 1:size(data)[1] ]
data_y = [ data_y[i]./sum(data_y[i]) for i in 1:size(data)[1] ]
M = 15 # number of PCA modes
data_x = [ [ data[i, j] for j in 11:(M+10) ] for i in 1:size(data)[1] ]

# partition the data
train = ([(data_x[i], data_y[i]) for i in partition(1:size(data)[1], 10)]) |> gpu
valset  = (length(data_x)-99:length(data_x))
valX = data_x[valset] |> gpu
valY = data_y[valset] |> gpu

#M = 25 # number of PCA modes
N = 5 # number of nodes in each hidden layer
ùí™ = 9 # number of output nodes
œµ = 1e-3 # small number to avoid log(0)

# Œ± = Chain(
# Dense(M => N, tanh),
# Dense(N => N, tanh),
# Dense(N => N, tanh),
# Dense(N => N, tanh),
# Dense(N => N, tanh),
# Dense(N => ùí™, exp)
# ) |> gpu

Œ± = Chain(
Dense(M => N, relu),
Dense(N => N, relu),
Dense(N => N, relu),
#Dense(N => N, relu),
#Dense(N => N, relu),
Dense(N => ùí™, sigmoid),
x->100*x .+1e-8 # need to scale this up (10 is more than enough)
) |> gpu

# define loss function
Log(x) = log.(x .+ œµ)
loss(x, y) = -loglikelihood(Dirichlet(Œ±(x) + (1e-8)*ones(ùí™)),[y]) # y is giving domain error problems??
Loss(x, y) = sum(loss.(x,y)) # total loss
opt = Adam()

# accuracy(x, y) = maximum(norm.(Œ±.(x)./sum.(Œ±.(x)).-y,1)) # accuracy function MAE (consider changing)
accuracy(x, y) = sum(abs.(norm.(Œ±.(x)./sum.(Œ±.(x)).-y,1)))

epochs = 10000 # number of epochs
# training loop
for epoch = 1:epochs 
    for d in train[1:Int64(floor(3*end/4))] #3/4 of the data
        gs = gradient(params(Œ±)) do 
            l = Loss(d...)
        end 
        Optimise.update!(opt, params(Œ±), gs)
        # println( maximum([ maximum(abs.(params(Œ±)[i])) for i in 1:length(params(Œ±)) ]) )
    end 
    # print accuracy wrt validation set
    @show accuracy(valX, valY)
    @show Loss(valX, valY)
    if isnan(Loss(valX, valY))
        break
    else
        BSON.@save "dirichlet-model.bson" model_state = Œ±
    end
end

# # plot results
# xt = [ train_x[i][1] for i in eachindex(train_x) ]
# x = 0.0:0.01:1.0
# for j in 1:3
#     # plot mean generating training data
#     Œº = [ map_xy(x[i])[j] for i in eachindex(x) ]./([ sum(map_xy(x[i])) for i in eachindex(x) ])
#     plot(x, Œº, label = "Œº$(j)")

#     # plot training data 
#     yt = [ train_y[i][j] for i in eachindex(train_x) ]
#     scatter!(xt, yt, label = "training data")

#     # plot model
#     a = [ Œ±([x[i]])[j] for i in eachindex(x) ]./([ sum(Œ±([x[i]])) for i in eachindex(x) ])
#     plot!(x, a, label = "model")

#     savefig("model_fit_$(j).png")
# end